---
permalink: false
report_parent: fy21

nav_order: 3
nav_label: "FY21 Project Showcase"
nav_id: "fy21-project-showcase"

class: light-gray

---
## FY21 Project Showcase

<p class="text-italic">We had a lot of projects that really inspired us in FY21 – projects we feel can – and do – deliver true impact for the public. For this year’s Impact Report, we’re focusing on one of the most exciting projects that blossomed during FY21: <span class="text-italic">Combating Bias in Artificial Intelligence and Machine Learning Implementations (AI/ML)</span>. To check out some of our other work, please head over to the [projects section of our site](../../projects/). It’s got the scoop on what we learned and the impact we’ve created through our individual projects.</p>

<div class="grid-row">
  <div class="grid-col-12 calloutProject">
    <h3>Combating Bias in AI/ML</h3>
  </div>
</div>

<p class="text-bold">How a 10x investment enshrines democratic principles in a changing govtech landscape</p>

Artificial Intelligence and Machine Learning (AI/ML) technologies will affect how the government serves the public. Public sector spending on AI is projected to reach well into the billions before long.<sup id="fnref-1"><a href="#fn-1" class="footnote-ref">1</a></sup> Federal CIOs have encouraged agencies to start experimenting with AI and two previous presidential administrations have all issued guidance, memoranda, or executive orders specific to AI adoption in government.

Despite all of this momentum, AI/ML technologies are fairly new to many government agencies. Many are still figuring out how these exciting new capabilities can support their business needs and how they can start adopting them.

We’ve funded several AI-related projects over the years and made some observations. We believe that AI/ML use in government is going to accelerate and it’s going to come with challenges. The stakes are high and the government needs to get it right the first time.

Stakes are high because AI/ML implementations risk harm if not done thoughtfully and ethically. These technologies help make real decisions that affect people’s lives, so fairness is a paramount concern. Enshrining democratic values like fairness, equity, and equality in AI/ML is a tall order. So where do we begin? How can we deliver impact here?

### Bias Toolkit

To meet this challenge, we placed a bet on the table: combating bias in upstream datasets — before they go through an AI pipeline that can make important decisions — is a good place to start.

Throughout FY21, the 10x team worked with the U.S. Census Bureau (Census) to develop the bias toolkit. This project along with our other AI-related projects, is how we’re helping the government get AI/ML right during these early days.

<p class="text-bold">What we delivered</p>

The toolkit includes three functioning de-biasing tools that federal employees can use to lay a more equitable foundation for their AI-enhanced workflows. Together, these three tools provide a great foundation for future de-biasing initiatives.

- The first tool creates carbon copies of datasets with placeholder (or ‘dummy’ data) that allows a federal employee to generate and test multiple, similar datasets through the AI model algorithm. Testing AI models with both real and placeholder data helps reveal sources of bias that might remain hidden if the model were trained only on the target dataset.

- The second tool uses AI to detect ableist language in federal job postings, which is language that may be offensive to people with disabilities. The tool automatically suggests more appropriate, inclusive alternatives that hiring managers can use to create better, more equitable job descriptions.

<div class="projectDemo">
  <video controls>
    <source src="{{ '/assets/images/impact-reports/ableist-ui-demo-800px-opt.mp4' | url }}" type="video/mp4" />
  </video>
</div>

- The third tool offers a standard language format, or model card, that describes the AI/ML model’s characteristics. Similar to a nutrition label on a can of soup that tells you the ingredients, nutritional profile, and allergen warnings, the model card shows the characteristics — including errors that could lead to biased outputs if left unaddressed – within that AI model. Model cards provide transparency about the AI model’s limitations and can help people re-use these models equitably and transparently.

The toolkit is currently in beta and awaiting a full launch in FY22. Census will own, maintain, and expand the toolkit. As the U.S. government’s premier statistical agency, Census works with the types of eye-poppingly large, complex datasets that power advanced AI, making them a great fit for championing this work into the future.

<p class="text-bold">Why we’re proud of this</p>

Everyone wins when a project is moved to where it can continue to thrive after exiting the 10x funding pipeline. An example of  how two agencies should work together, it’s a great project transition that will have a huge impact.

We showcase this de-biasing project because we believe it resonates with communities outside of our core user base of federal employees. This project lives at the intersection of two of the most important conversations that we, as a country, are having and highlights how the government is responding. The first conversation focuses on reckoning with injustice in our society as experienced by minority and vulnerable populations. The second is the rapidly evolving field of artificial intelligence and the cultural angst around how AI and other emerging technologies will affect society (for better or worse) in the years to come.

We’re proud of this project and we’re proud that we helped ensure that the government adopts rapidly advancing, powerful technologies in a way that shows a serious effort to protect democratic values and delivers positive, meaningful impact for the public. We are excited to see it grow and mature under the stewardship of our U.S. Census Bureau partners. Be on the lookout for the full roll-out in 2022, we’ll keep our site updated. In the meantime, the initial toolkit is open-source and available freely on the web. Anyone in the world can find, use, and contribute to our tools.

<p class="text-bold">Summary</p>

10x is a small program within our own agency and we are only one of many initiatives across the government that are also thinking about the future of AI/ML in public service delivery. Naturally, the private sector and other groups will play a central role in the future of public sector AI/ML adoption. But we believe the government has a special role to play.

Our ambition for this project was to make small, positive interventions that reinforced democratic values of justice and equity as the government adopts AI/ML. We aim to create positive ripple effects that will carry into the future and influence how the government uses AI to serve the public.
